{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7057f38",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/BagelIndexDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a2a63",
   "metadata": {},
   "source": [
    "# Bagel Network\n",
    "\n",
    ">[Bagel](https://docs.bageldb.ai/) is a Open Inference Data for AI. It is built for distributed Machine Learning compute. Cutting AI data infra spend by tenfold.\n",
    "\n",
    "<a href=\"https://discord.gg/bA7B6r97\" target=\"_blank\">\n",
    "      <img src=\"https://img.shields.io/discord/1073293645303795742\" alt=\"Discord\">\n",
    "  </a>&nbsp;&nbsp;\n",
    "\n",
    "\n",
    "- [Website](https://www.bageldb.ai/)\n",
    "- [Documentation](https://docs.bageldb.ai/)\n",
    "- [Twitter](https://twitter.com/bageldb_ai)\n",
    "- [Discord](https://discord.gg/bA7B6r97)\n",
    "\n",
    "\n",
    "Install Bagel with:\n",
    "\n",
    "```sh\n",
    "pip install bagelML\n",
    "```\n",
    "\n",
    "\n",
    "Like any other database, you can:\n",
    "- `.add` \n",
    "- `.get` \n",
    "- `.delete`\n",
    "- `.update`\n",
    "- `.upsert`\n",
    "- `.peek`\n",
    "- `.modify`\n",
    "- and `.find` runs the similarity search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a9dc8",
   "metadata": {},
   "source": [
    "## Basic Example\n",
    "\n",
    "In this basic example, we take the a Paul Graham essay, split it into chunks, embed it using an open-source embedding model, load it into Bagel, and then query it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d325a363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-vector-stores-bagel in /Users/polas/anaconda3/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-vector-stores-bagel) (0.10.26)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (0.1.16)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.16.1)\n",
      "Requirement already satisfied: pandas in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.14.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.8.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.10.14)\n",
      "Requirement already satisfied: anyio in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/polas/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.21.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/polas/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-vector-stores-bagel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0030cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\n",
      "  Obtaining dependency information for llama-index-embeddings-huggingface from https://files.pythonhosted.org/packages/87/f6/ab24b323f09525ce37e0553c2e487bae477207a61b836a501560fb17120c/llama_index_embeddings_huggingface-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_embeddings_huggingface-0.2.0-py3-none-any.whl.metadata (725 bytes)\n",
      "Collecting huggingface-hub[inference]>=0.19.0 (from llama-index-embeddings-huggingface)\n",
      "  Obtaining dependency information for huggingface-hub[inference]>=0.19.0 from https://files.pythonhosted.org/packages/05/c0/779afbad8e75565c09ffa24a88b5dd7e293c92b74eb09df6435fc58ac986/huggingface_hub-0.22.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.10.26)\n",
      "Collecting sentence-transformers<3.0.0,>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Obtaining dependency information for sentence-transformers<3.0.0,>=2.6.1 from https://files.pythonhosted.org/packages/ba/20/7ef81df2e07322d95332d07c1c38c597f543c1f666d689a3153ba6fa09e3/sentence_transformers-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /Users/polas/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/polas/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/polas/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/polas/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.3)\n",
      "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Obtaining dependency information for minijinja>=1.0 from https://files.pythonhosted.org/packages/ce/66/0e98b4d2903a4591e168b973ade3df7450566872b72bb13209f3d698455f/minijinja-1.0.16-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata\n",
      "  Downloading minijinja-1.0.16-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.29)\n",
      "Requirement already satisfied: dataclasses-json in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.1.16)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.1)\n",
      "Requirement already satisfied: pandas in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (10.2.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Collecting transformers<5.0.0,>=4.32.0 (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.32.0 from https://files.pythonhosted.org/packages/15/fc/7b6dd7e1adc0a6407b845ed4be1999e98b6917d0694e57316d140cc85484/transformers-4.39.3-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m425.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/polas/anaconda3/lib/python3.11/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/polas/anaconda3/lib/python3.11/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.11.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.8.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic>=1.10 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.10.14)\n",
      "Requirement already satisfied: anyio in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/polas/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.1)\n",
      "Requirement already satisfied: sympy in /Users/polas/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.1.2)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.32.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/5f/4f/a4c12cc058a899c1caaa1e689c3df9a698e20e891d4005aa6ec2174a9339/tokenizers-0.15.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tokenizers-0.15.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.32.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/03/a0/67f2ed19dbc609ce1bf561a285a6cc8f804846a7f4d9c46b403be93022e4/safetensors-0.4.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.4.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/polas/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/polas/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Downloading llama_index_embeddings_huggingface-0.2.0-py3-none-any.whl (7.1 kB)\n",
      "Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m373.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m266.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading minijinja-1.0.16-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m211.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m431.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp311-cp311-macosx_11_0_arm64.whl (393 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.4/393.4 kB\u001b[0m \u001b[31m108.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m180.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, minijinja, huggingface-hub, tokenizers, transformers, sentence-transformers, llama-index-embeddings-huggingface\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.2\n",
      "    Uninstalling safetensors-0.3.2:\n",
      "      Successfully uninstalled safetensors-0.3.2\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed huggingface-hub-0.22.2 llama-index-embeddings-huggingface-0.2.0 minijinja-1.0.16 safetensors-0.4.2 sentence-transformers-2.6.1 tokenizers-0.15.2 transformers-4.39.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-embeddings-huggingface\n",
    "!pip install bagelML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb203c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.bagel import BagelVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from IPython.display import Markdown, display\n",
    "import bagel\n",
    "from bagel import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdb122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key:········\n"
     ]
    }
   ],
   "source": [
    "# set up OpenAI\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4456726",
   "metadata": {},
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd2e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-04 14:51:21--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... ^C\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87cfd091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a9e713b423407799911df0b76c70b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82018984d294853a21800c368475bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a38528d7f2445148e5d160068d96a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfa7de414624a2c92ba605df0a41b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3689284b9f47e487f446ed8a1b6541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ed81be5dfa4c9aa6bc4223ad291bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a062e1cc77134511b03eb0f800a6b7de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f03f9d3cd444a7980c608d426b7f2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b2612166ca498b96618f4d241370ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6169a21316a94f93b3ae246334dd8c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345d3c41cf6d4bc7af9e43ac4a6ca1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>The author worked on writing short stories and programming, particularly on an IBM 1401 using an early version of Fortran during his time in 9th grade. Later, he transitioned to working with microcomputers, starting with a TRS-80 in 1980, where he wrote simple games, programs, and even a word processor.</b>\n"
     ]
    }
   ],
   "source": [
    "# create server settings\n",
    "server_settings = Settings(\n",
    "    bagel_api_impl=\"rest\", bagel_server_host=\"api.bageldb.ai\"\n",
    ")\n",
    "\n",
    "# create client\n",
    "client = bagel.Client(server_settings)\n",
    "\n",
    "# create collection\n",
    "collection = client.get_or_create_cluster(\"testing_embeddings\", embedding_model='custom', dimension=384)\n",
    "\n",
    "# define embedding function\n",
    "embed_model = \"local:BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n",
    "\n",
    "# set up BagelVectorStore and load in data\n",
    "vector_store = BagelVectorStore(collection=collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, embed_model=embed_model\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(f\"<b>{response}</b>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45be6f8",
   "metadata": {},
   "source": [
    "## Create - Add - Get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ffc8240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_add_get(client):\n",
    "    \"\"\"\n",
    "    Create, add, and get\n",
    "    \"\"\"\n",
    "    name = \"testing\"\n",
    "\n",
    "    # Get or create a cluster\n",
    "    cluster = client.get_or_create_cluster(name)\n",
    "\n",
    "    # Add documents to the cluster\n",
    "    resp = cluster.add(\n",
    "        documents=[\n",
    "            \"This is document1\",\n",
    "            \"This is bidhan\",\n",
    "        ],\n",
    "        metadatas=[{\"source\": \"google\"}, {\"source\": \"notion\"}],\n",
    "        ids=[str(uuid.uuid4()), str(uuid.uuid4())],\n",
    "    )\n",
    "\n",
    "    # Print count\n",
    "    print(\"count of docs:\", cluster.count())\n",
    "\n",
    "    # Get the first item\n",
    "    first_item = cluster.peek(1)\n",
    "    if first_item:\n",
    "        print(\"get 1st item\")\n",
    "\n",
    "    print(\">> create_add_get done !\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0517c3da",
   "metadata": {},
   "source": [
    "## Create - Add - Find by Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9047a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_add_find(client):\n",
    "    \"\"\"\n",
    "    Create, add, & find\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    api : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    name = \"testing\"\n",
    "\n",
    "    # Get or create a cluster\n",
    "    cluster = client.get_or_create_cluster(name)\n",
    "\n",
    "    # Add documents to the cluster\n",
    "    cluster.add(\n",
    "        documents=[\n",
    "            \"This is document\",\n",
    "            \"This is Towhid\",\n",
    "            \"This is text\",\n",
    "        ],\n",
    "        metadatas=[\n",
    "            {\"source\": \"notion\"},\n",
    "            {\"source\": \"notion\"},\n",
    "            {\"source\": \"google-doc\"},\n",
    "        ],\n",
    "        ids=[str(uuid.uuid4()), str(uuid.uuid4()), str(uuid.uuid4())],\n",
    "    )\n",
    "\n",
    "    # Query the cluster for similar results\n",
    "    results = cluster.find(\n",
    "        query_texts=[\"This\"],\n",
    "        n_results=5,\n",
    "        where={\"source\": \"notion\"},\n",
    "        where_document={\"$contains\": \"is\"},\n",
    "    )\n",
    "\n",
    "    print(results)\n",
    "    print(\">> create_add_find done  !\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e7f85",
   "metadata": {},
   "source": [
    "## Create - Add - Find by Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de58cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_add_find_em(client):\n",
    "    \"\"\"Create, add, & find embeddings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    api : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    name = \"testing_embeddings\"\n",
    "    # Reset the Bagel server\n",
    "    client.reset()\n",
    "\n",
    "    # Get or create a cluster\n",
    "    cluster = api.get_or_create_cluster(name)\n",
    "    # Add embeddings and other data to the cluster\n",
    "    cluster.add(\n",
    "        embeddings=[\n",
    "            [1.1, 2.3, 3.2],\n",
    "            [4.5, 6.9, 4.4],\n",
    "            [1.1, 2.3, 3.2],\n",
    "            [4.5, 6.9, 4.4],\n",
    "            [1.1, 2.3, 3.2],\n",
    "            [4.5, 6.9, 4.4],\n",
    "            [1.1, 2.3, 3.2],\n",
    "            [4.5, 6.9, 4.4],\n",
    "        ],\n",
    "        metadatas=[\n",
    "            {\"uri\": \"img1.png\", \"style\": \"style1\"},\n",
    "            {\"uri\": \"img2.png\", \"style\": \"style2\"},\n",
    "            {\"uri\": \"img3.png\", \"style\": \"style1\"},\n",
    "            {\"uri\": \"img4.png\", \"style\": \"style1\"},\n",
    "            {\"uri\": \"img5.png\", \"style\": \"style1\"},\n",
    "            {\"uri\": \"img6.png\", \"style\": \"style1\"},\n",
    "            {\"uri\": \"img7.png\", \"style\": \"style1\"},\n",
    "            {\"uri\": \"img8.png\", \"style\": \"style1\"},\n",
    "        ],\n",
    "        documents=[\n",
    "            \"doc1\",\n",
    "            \"doc2\",\n",
    "            \"doc3\",\n",
    "            \"doc4\",\n",
    "            \"doc5\",\n",
    "            \"doc6\",\n",
    "            \"doc7\",\n",
    "            \"doc8\",\n",
    "        ],\n",
    "        ids=[\"id1\", \"id2\", \"id3\", \"id4\", \"id5\", \"id6\", \"id7\", \"id8\"],\n",
    "    )\n",
    "\n",
    "    # Query the cluster for results\n",
    "    results = cluster.find(query_embeddings=[[1.1, 2.3, 3.2]], n_results=5)\n",
    "\n",
    "    print(\"find result:\", results)\n",
    "    print(\">> create_add_find_em done  !\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a08fa4",
   "metadata": {},
   "source": [
    "## Create - Add - Modify - Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b0ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_add_modify_update(client):\n",
    "    \"\"\"\n",
    "    Create, add, modify, and update\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    api : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    name = \"testing\"\n",
    "    new_name = \"new_\" + name\n",
    "\n",
    "    # Get or create a cluster\n",
    "    cluster = client.get_or_create_cluster(name)\n",
    "\n",
    "    # Modify the cluster name\n",
    "    print(\"Before:\", cluster.name)\n",
    "    cluster.modify(name=new_name)\n",
    "    print(\"After:\", cluster.name)\n",
    "\n",
    "    # Add documents to the cluster\n",
    "    cluster.add(\n",
    "        documents=[\n",
    "            \"This is document1\",\n",
    "            \"This is bidhan\",\n",
    "        ],\n",
    "        metadatas=[{\"source\": \"notion\"}, {\"source\": \"google\"}],\n",
    "        ids=[\"id1\", \"id2\"],\n",
    "    )\n",
    "\n",
    "    # Retrieve document metadata before updating\n",
    "    print(\"Before update:\")\n",
    "    print(cluster.get(ids=[\"id1\"]))\n",
    "\n",
    "    # Update document metadata\n",
    "    cluster.update(ids=[\"id1\"], metadatas=[{\"source\": \"google\"}])\n",
    "\n",
    "    # Retrieve document metadata after updating\n",
    "    print(\"After update source:\")\n",
    "    print(cluster.get(ids=[\"id1\"]))\n",
    "\n",
    "    print(\">> create_add_modify_update done !\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc867a",
   "metadata": {},
   "source": [
    "## Create - Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587ccb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_upsert(client):\n",
    "    \"\"\"\n",
    "    Create and upsert\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    api : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    # Reset the Bagel server\n",
    "    api.reset()\n",
    "\n",
    "    name = \"testing\"\n",
    "\n",
    "    # Get or create a cluster\n",
    "    cluster = client.get_or_create_cluster(name)\n",
    "\n",
    "    # Add documents to the cluster\n",
    "    cluster.add(\n",
    "        documents=[\n",
    "            \"This is document1\",\n",
    "            \"This is bidhan\",\n",
    "        ],\n",
    "        metadatas=[{\"source\": \"notion\"}, {\"source\": \"google\"}],\n",
    "        ids=[\"id1\", \"id2\"],\n",
    "    )\n",
    "\n",
    "    # Upsert documents in the cluster\n",
    "    cluster.upsert(\n",
    "        documents=[\n",
    "            \"This is document\",\n",
    "            \"This is google\",\n",
    "        ],\n",
    "        metadatas=[{\"source\": \"notion\"}, {\"source\": \"google\"}],\n",
    "        ids=[\"id1\", \"id3\"],\n",
    "    )\n",
    "\n",
    "    # Print the count of documents in the cluster\n",
    "    print(\"Count of documents:\", cluster.count())\n",
    "    print(\">> create_upsert done !\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e42d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
