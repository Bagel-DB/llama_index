{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4f9a0f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/BagelAutoRetriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
   "metadata": {},
   "source": [
    "# Bagel Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15119a5b",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d497859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-bagel\n",
      "  Obtaining dependency information for llama-index-vector-stores-bagel from https://files.pythonhosted.org/packages/ee/8e/071300ed9f1304f78553253bcbf34a7f6832afe6ac0b0c4b6d5a01e47a9f/llama_index_vector_stores_bagel-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_vector_stores_bagel-0.1.2-py3-none-any.whl.metadata (660 bytes)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for llama-index-core<0.11.0,>=0.10.1 from https://files.pythonhosted.org/packages/95/42/ab4f99ac9422359c6e56d6dfcbe29dbd96d3fca81bc2f170658160d4fd7d/llama_index_core-0.10.26-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_core-0.10.26-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for PyYAML>=6.0.1 from https://files.pythonhosted.org/packages/28/09/55f715ddbf95a054b764b547f617e22f1d5e45d83905660e9a088078fe67/PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy[asyncio]>=1.4.49 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for SQLAlchemy[asyncio]>=1.4.49 from https://files.pythonhosted.org/packages/ea/3e/95278ef021d3b8bed98bcc5f10faf27e4c4bc0a63a6e0bd98529b1ba8d2e/SQLAlchemy-2.0.29-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.29-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.6 from https://files.pythonhosted.org/packages/d3/b0/efb74d5f92a460c774e0254b3109c2d00fd3a1553f98363abb2b25cac9a3/aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for dataclasses-json from https://files.pythonhosted.org/packages/91/ca/7219b838086086972e662c19e908694bdc6744537fb41b70392501b8b5e4/dataclasses_json-0.6.4-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for deprecated>=1.2.9.3 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for dirtyjson<2.0.0,>=1.0.8 from https://files.pythonhosted.org/packages/68/69/1bcf70f81de1b4a9f21b3a62ec0c83bdff991c88d6cc2267d02408457e88/dirtyjson-1.0.8-py3-none-any.whl.metadata\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/93/6d/66d48b03460768f523da62a57a7e14e5e95fdf339d79e996ce3cecda2cdb/fsspec-2024.3.1-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for httpx from https://files.pythonhosted.org/packages/41/7b/ddacf6dcebb42466abd03f368782142baa82e08fc0c1f8eaa05b4bae87d5/httpx-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.15 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for llamaindex-py-client<0.2.0,>=0.1.15 from https://files.pythonhosted.org/packages/ee/68/f797e917ee57a17943115e1f232221c5aa690f779fa44f45af7fcaf3792f/llamaindex_py_client-0.1.16-py3-none-any.whl.metadata\n",
      "  Downloading llamaindex_py_client-0.1.16-py3-none-any.whl.metadata (711 bytes)\n",
      "Collecting nest-asyncio<2.0.0,>=1.5.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for nest-asyncio<2.0.0,>=1.5.8 from https://files.pythonhosted.org/packages/a0/c4/c2971a3ba4c6103a3d10c4b0f24f461ddc027f0f09763220cf35ca1401b3/nest_asyncio-1.6.0-py3-none-any.whl.metadata\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.1)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for nltk<4.0.0,>=3.8.1 from https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.24.3)\n",
      "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for openai>=1.1.0 from https://files.pythonhosted.org/packages/9e/7f/99e27538e3916c30150a032debb9bd06ada8b2310ff1d3a88618b9137df4/openai-1.16.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.16.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: pandas in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (8.2.2)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for tiktoken>=0.3.3 from https://files.pythonhosted.org/packages/9e/11/83ca4e19bb6fc15971e543725ae1269a8a1c133e55b5952801ab9c0bcc9e/tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for tqdm<5.0.0,>=4.66.1 from https://files.pythonhosted.org/packages/2a/14/e75e52d521442e2fcc9f1df3c5e456aead034203d4797867980de558ab34/tqdm-4.66.2-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m676.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (4.9.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for typing-inspect>=0.8.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wrapt in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.14.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.8.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.10.14)\n",
      "Requirement already satisfied: anyio in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/78/d4/e5d7e4f2174f8a4d63c8897d79eb8fe2503f7ecc03282fee1fa2719c2704/httpcore-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.2.0)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/h11/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x103cfed90>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/h11/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: click in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2022.7.9)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/polas/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.0.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/38/04/37055b7013dfaaf66e3a9a51e46857cc9be151476a891b995fa70da7e139/marshmallow-3.21.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/polas/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-bagel) (1.16.0)\n",
      "Downloading llama_index_vector_stores_bagel-0.1.2-py3-none-any.whl (3.1 kB)\n",
      "Downloading llama_index_core-0.10.26-py3-none-any.whl (15.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl (387 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m387.7/387.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llamaindex_py_client-0.1.16-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hDownloading openai-1.16.1-py3-none-any.whl (266 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m266.9/266.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m167.5/167.5 kB\u001b[0m \u001b[31m696.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl (949 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.29-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dirtyjson, typing-inspect, tqdm, SQLAlchemy, PyYAML, nest-asyncio, marshmallow, h11, fsspec, distro, deprecated, tiktoken, nltk, httpcore, dataclasses-json, aiohttp, httpx, openai, llamaindex-py-client, llama-index-core, llama-index-vector-stores-bagel\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.39\n",
      "    Uninstalling SQLAlchemy-1.4.39:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.39\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.6\n",
      "    Uninstalling nest-asyncio-1.5.6:\n",
      "      Successfully uninstalled nest-asyncio-1.5.6\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.6.7\n",
      "    Uninstalling nltk-3.6.7:\n",
      "      Successfully uninstalled nltk-3.6.7\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.5\n",
      "    Uninstalling aiohttp-3.8.5:\n",
      "      Successfully uninstalled aiohttp-3.8.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "label-studio 1.11.0 requires pytz<2023.0,>=2022.1, but you have pytz 2024.1 which is incompatible.\n",
      "label-studio-converter 0.0.57 requires nltk==3.6.7, but you have nltk 3.8.1 which is incompatible.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.3.1 which is incompatible.\n",
      "aiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.34.54 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.1 SQLAlchemy-2.0.29 aiohttp-3.9.3 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 fsspec-2024.3.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-core-0.10.26 llama-index-vector-stores-bagel-0.1.2 llamaindex-py-client-0.1.16 marshmallow-3.21.1 nest-asyncio-1.6.0 nltk-3.8.1 openai-1.16.1 tiktoken-0.6.0 tqdm-4.66.2 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-vector-stores-bagel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb74914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Obtaining dependency information for llama-index from https://files.pythonhosted.org/packages/5c/bb/2d9364cc348c3d3e71a469bf1e2f3ab9219fecbee8dab4cc08ccb16b0e06/llama_index-0.10.26-py3-none-any.whl.metadata\n",
      "  Downloading llama_index-0.10.26-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-agent-openai<0.3.0,>=0.1.4 from https://files.pythonhosted.org/packages/70/f1/31bbdac7719ed492ab98b1e5e48914af79c344eb6b08a4727d80416329cc/llama_index_agent_openai-0.2.2-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_agent_openai-0.2.2-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-cli<0.2.0,>=0.1.2 from https://files.pythonhosted.org/packages/cf/77/1003907d0b46e2d793ed1db8933371f9e9991a938684eb01c26b86518321/llama_index_cli-0.1.11-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_cli-0.1.11-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.26 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index) (0.10.26)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-embeddings-openai<0.2.0,>=0.1.5 from https://files.pythonhosted.org/packages/e4/d6/4623eb16f0e4ba2a716747f824451548ac5618f4093e1d0a9e0c66771e64/llama_index_embeddings_openai-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_embeddings_openai-0.1.7-py3-none-any.whl.metadata (603 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 from https://files.pythonhosted.org/packages/d5/4b/57282bc69de0ac29dfa170f491320836b58a3798c30b218dc3629326d13a/llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-legacy<0.10.0,>=0.9.48 from https://files.pythonhosted.org/packages/02/0a/0da9d27b0c3b074c1be1151ff4a4558f077c93df463310adfb47d193dde2/llama_index_legacy-0.9.48-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-llms-openai<0.2.0,>=0.1.13 from https://files.pythonhosted.org/packages/3b/cb/770e12e50bb67f0875c4e640391d9994859f1c51bfb436befc3aa6395e19/llama_index_llms_openai-0.1.14-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_llms_openai-0.1.14-py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 from https://files.pythonhosted.org/packages/25/95/5ae22be545a28b12439a790f0672e41f4bfb50b8c2d1719038c05f5fe7a2/llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-program-openai<0.2.0,>=0.1.3 from https://files.pythonhosted.org/packages/de/95/a9a9db9c040917aeffdafc9be5d2bc9f3616a2710be60927fa6adddeb1e0/llama_index_program_openai-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_program_openai-0.1.5-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-question-gen-openai<0.2.0,>=0.1.2 from https://files.pythonhosted.org/packages/2d/22/39f3ac5702b0e8ffd4d5a383c7cb2da0eb60f63b95f739345e79b66bf977/llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-readers-file<0.2.0,>=0.1.4 from https://files.pythonhosted.org/packages/32/8f/7f0004677f586ca96083c255ba629cb56ebcefeee8bc6a375d51cce0cfe4/llama_index_readers_file-0.1.13-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_readers_file-0.1.13-py3-none-any.whl.metadata (934 bytes)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-readers-llama-parse<0.2.0,>=0.1.2 from https://files.pythonhosted.org/packages/79/af/e9aaf5e8869dd8a759b83ab8847cfb84642f3f583332a1786b49c691bbc6/llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.16.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.1.16)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.24.3)\n",
      "Requirement already satisfied: pandas in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/polas/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.14.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Obtaining dependency information for beautifulsoup4<5.0.0,>=4.12.3 from https://files.pythonhosted.org/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Obtaining dependency information for pymupdf<2.0.0,>=1.23.21 from https://files.pythonhosted.org/packages/d2/9e/0dc8b8dd14d456d0b45a8755307aca81d357def8ab4fe551e58571f9f5f5/PyMuPDF-1.24.1-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading PyMuPDF-1.24.1-cp311-none-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Obtaining dependency information for pypdf<5.0.0,>=4.0.1 from https://files.pythonhosted.org/packages/b8/1e/071b6684ee2b299a74a0bcdbf9a5441a1002920c72b6990b445d45c2b956/pypdf-4.1.0-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-4.1.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Obtaining dependency information for striprtf<0.0.27,>=0.0.26 from https://files.pythonhosted.org/packages/a3/cf/0fea4f4ba3fc2772ac2419278aa9f6964124d4302117d61bc055758e000c/striprtf-0.0.26-py3-none-any.whl.metadata\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Obtaining dependency information for llama-parse<0.5.0,>=0.4.0 from https://files.pythonhosted.org/packages/62/2b/4246819740967f6d57d6d86f523977e5660a81f6314af129bacdd870cbf0/llama_parse-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_parse-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.8.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/polas/anaconda3/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.10.14)\n",
      "Requirement already satisfied: anyio in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/polas/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/polas/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\n",
      "Collecting PyMuPDFb==1.24.1 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Obtaining dependency information for PyMuPDFb==1.24.1 from https://files.pythonhosted.org/packages/bc/56/f3bf6af49c03833bfae026feaf6980759df48bee5e0ca653ee3c591df81a/PyMuPDFb-1.24.1-py3-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading PyMuPDFb-1.24.1-py3-none-macosx_11_0_arm64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/polas/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/polas/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/polas/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.26->llama-index) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/polas/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.16.0)\n",
      "Downloading llama_index-0.10.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_agent_openai-0.2.2-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_cli-0.1.11-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_embeddings_openai-0.1.7-py3-none-any.whl (6.0 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl (6.7 kB)\n",
      "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.1.14-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
      "Downloading llama_index_program_openai-0.1.5-py3-none-any.whl (4.1 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.13-py3-none-any.whl (36 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_parse-0.4.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading PyMuPDF-1.24.1-cp311-none-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDFb-1.24.1-py3-none-macosx_11_0_arm64.whl (29.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m807.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: striprtf, pypdf, PyMuPDFb, beautifulsoup4, pymupdf, llama-index-legacy, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.12.2\n",
      "    Uninstalling beautifulsoup4-4.12.2:\n",
      "      Successfully uninstalled beautifulsoup4-4.12.2\n",
      "Successfully installed PyMuPDFb-1.24.1 beautifulsoup4-4.12.3 llama-index-0.10.26 llama-index-agent-openai-0.2.2 llama-index-cli-0.1.11 llama-index-embeddings-openai-0.1.7 llama-index-indices-managed-llama-cloud-0.1.5 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.14 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.5 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.13 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.0 pymupdf-1.24.1 pypdf-4.1.0 striprtf-0.0.26\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd70964",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bagelML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48af8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf49ac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key:路路路路路路路路\n"
     ]
    }
   ],
   "source": [
    "# set up OpenAI\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "465aef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagel API Key:路路路路路路路路\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variable\n",
    "os.environ['BAGEL_API_KEY'] = getpass.getpass(\"Bagel API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ce3143d-198c-4dd2-8e5a-c5cdf94f017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bagel\n",
    "from bagel import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "667f3cb3-ce18-48d5-b9aa-bfc1a1f0f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_settings = Settings(\n",
    "    bagel_api_impl=\"rest\", bagel_server_host=\"api.bageldb.ai\"\n",
    ")\n",
    "\n",
    "client = bagel.Client(server_settings)\n",
    "\n",
    "collection = client.get_or_create_cluster(\"testing_embeddings_3\", embedding_model='custom', dimension=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a2bcc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.bagel import BagelVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"Michael Jordan is a retired professional basketball player,\"\n",
    "            \" widely regarded as one of the greatest basketball players of all\"\n",
    "            \" time.\"\n",
    "        ),\n",
    "        metadata={\n",
    "            \"category\": \"Sports\",\n",
    "            \"country\": \"United States\",\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"Angelina Jolie is an American actress, filmmaker, and\"\n",
    "            \" humanitarian. She has received numerous awards for her acting\"\n",
    "            \" and is known for her philanthropic work.\"\n",
    "        ),\n",
    "        metadata={\n",
    "            \"category\": \"Entertainment\",\n",
    "            \"country\": \"United States\",\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"Elon Musk is a business magnate, industrial designer, and\"\n",
    "            \" engineer. He is the founder, CEO, and lead designer of SpaceX,\"\n",
    "            \" Tesla, Inc., Neuralink, and The Boring Company.\"\n",
    "        ),\n",
    "        metadata={\n",
    "            \"category\": \"Business\",\n",
    "            \"country\": \"United States\",\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"Rihanna is a Barbadian singer, actress, and businesswoman. She\"\n",
    "            \" has achieved significant success in the music industry and is\"\n",
    "            \" known for her versatile musical style.\"\n",
    "        ),\n",
    "        metadata={\n",
    "            \"category\": \"Music\",\n",
    "            \"country\": \"Barbados\",\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"Cristiano Ronaldo is a Portuguese professional footballer who is\"\n",
    "            \" considered one of the greatest football players of all time. He\"\n",
    "            \" has won numerous awards and set multiple records during his\"\n",
    "            \" career.\"\n",
    "        ),\n",
    "        metadata={\n",
    "            \"category\": \"Sports\",\n",
    "            \"country\": \"Portugal\",\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba1558b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = BagelVectorStore(collection=collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35369eda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexAutoRetriever\n",
    "from llama_index.core.vector_stores import MetadataInfo, VectorStoreInfo\n",
    "\n",
    "\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"brief biography of celebrities\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"category\",\n",
    "            type=\"str\",\n",
    "            description=(\n",
    "                \"Category of the celebrity, one of [Sports, Entertainment,\"\n",
    "                \" Business, Music]\"\n",
    "            ),\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"country\",\n",
    "            type=\"str\",\n",
    "            description=(\n",
    "                \"Country of the celebrity, one of [United States, Barbados,\"\n",
    "                \" Portugal]\"\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "retriever = VectorIndexAutoRetriever(\n",
    "    index, vector_store_info=vector_store_info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eeb18e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using query str: celebrity\n",
      "Using query str: celebrity\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using filters: []\n",
      "Using filters: []\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using top_k: 2\n",
      "Using top_k: 2\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='1c5e9a08-8718-4807-9918-c08424ee18b2', embedding=None, metadata={'category': 'Entertainment', 'country': 'United States'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5130916175579987),\n",
       " NodeWithScore(node=TextNode(id_='9809a85d-050e-451c-8398-987448b8dcfc', embedding=None, metadata={'category': 'Sports', 'country': 'United States'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.4981991494232819)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.retrieve(\"celebrity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741264a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ac390d292208ca2380c85f5bce7ded36a7a25670a97c40b8009630eb36cb06e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
